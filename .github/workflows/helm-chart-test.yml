name: Helm Chart Quality Test

# This workflow tests the ROS-OCP Helm chart deployment on Kind
# Uses alternative registries to avoid Docker Hub rate limiting:
# - public.ecr.aws for official images (postgres, redis, busybox, confluent)
# - quay.io for application images (already configured)
# - ghcr.io as fallback for some images

on:
  pull_request:
    paths:
      - 'deployment/kubernetes/helm/**'
      - 'deployment/kubernetes/scripts/**'
      - '.github/workflows/helm-chart-test*.yml'
  push:
    branches:
      - add_ocp_support
    paths:
      - 'deployment/kubernetes/helm/**'
      - 'deployment/kubernetes/scripts/**'
      - '.github/workflows/helm-chart-test*.yml'
  workflow_dispatch:

jobs:
  helm-chart-test:
    name: Test Helm Chart Deployment
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      CONTAINER_RUNTIME: podman

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Log in to Public ECR
        run: |
          # Login to public.ecr.aws (no authentication required for public images, but login for higher rate limits)
          aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws 2>/dev/null || echo "Public ECR login failed, continuing without auth"
        env:
          AWS_DEFAULT_REGION: us-east-1

      - name: Install Podman
        run: |
          # Install Podman
          sudo apt-get update
          sudo apt-get install -y podman

          # Verify Podman installation
          echo "Podman version:"
          podman --version
          echo "Podman info:"
          podman info
          echo "Testing Podman connectivity:"
          podman run --rm quay.io/podman/hello

      - name: Install KIND
        run: |
          # Get the latest KIND version
          KIND_VERSION=$(curl -s https://api.github.com/repos/kubernetes-sigs/kind/releases/latest | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\1/')
          echo "Latest KIND version: $KIND_VERSION"

          # Download and install the latest KIND version
          curl -Lo ./kind "https://kind.sigs.k8s.io/dl/${KIND_VERSION}/kind-linux-amd64"
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

          # Verify installation
          kind version

          # Configure Kind to use Podman explicitly
          echo "Podman driver will be used by Kind"

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl
          kubectl version --client

      - name: Install Helm
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version

      - name: Set up environment and Podman configuration
        run: |
          echo "KIND_CLUSTER_NAME=ros-ocp-test-cluster" >> $GITHUB_ENV
          echo "HELM_RELEASE_NAME=ros-ocp-test" >> $GITHUB_ENV
          echo "NAMESPACE=ros-ocp-test" >> $GITHUB_ENV

      - name: Setup KIND cluster
        timeout-minutes: 15
        run: |
          cd deployment/kubernetes/scripts
          export KIND_CLUSTER_NAME=${{ env.KIND_CLUSTER_NAME }}
          export HELM_RELEASE_NAME=${{ env.HELM_RELEASE_NAME }}
          export NAMESPACE=${{ env.NAMESPACE }}

          # Make scripts executable
          chmod +x deploy-kind.sh

          # Setup KIND cluster
          echo "Setting up KIND cluster..."
          ./deploy-kind.sh

          # Verify cluster is running
          echo "Verifying cluster status..."
          kind get clusters
          kubectl cluster-info
          kubectl get nodes -o wide


      - name: Deploy Helm Chart
        timeout-minutes: 15
        run: |
          # Trigger new build to test MinIO buckets job fix
          cd deployment/kubernetes/scripts
          export KIND_CLUSTER_NAME=${{ env.KIND_CLUSTER_NAME }}
          export HELM_RELEASE_NAME=${{ env.HELM_RELEASE_NAME }}
          export NAMESPACE=${{ env.NAMESPACE }}

          # Make scripts executable
          chmod +x install-helm-chart.sh

          # Deploy Helm chart
          echo "Deploying Helm chart..."
          ./install-helm-chart.sh

          # Verify deployment
          echo "Verifying Helm chart deployment..."
          kubectl get pods -n $NAMESPACE
          kubectl get services -n $NAMESPACE
          kubectl get ingress -n $NAMESPACE

      - name: Wait for services to stabilize
        run: |
          echo "Waiting for services to stabilize..."

          # Wait for all pods to be in Running state
          timeout 600 bash -c "until kubectl wait --for=condition=ready pod -l 'app.kubernetes.io/instance=${{ env.HELM_RELEASE_NAME }}' -n ${{ env.NAMESPACE }} --timeout=30s; do echo 'Waiting for pods...'; sleep 10; done"

          # Additional wait for services to fully initialize
          echo "All pods ready, waiting additional 30 seconds for service initialization..."
          sleep 30

      - name: Verify cluster and services health
        run: |
          echo "=== Cluster Health Check ==="
          kubectl get nodes -o wide
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide
          kubectl get services -n ${{ env.NAMESPACE }}

          echo "=== Container Status ==="
          ${{ env.CONTAINER_RUNTIME }} ps --filter "label=io.x-k8s.kind.cluster=${{ env.KIND_CLUSTER_NAME }}"

          echo "=== Resource Usage ==="
          df -h
          free -h

      - name: Run Dataflow Test
        timeout-minutes: 15
        run: |
          cd deployment/kubernetes/scripts
          export KIND_CLUSTER_NAME=${{ env.KIND_CLUSTER_NAME }}
          export HELM_RELEASE_NAME=${{ env.HELM_RELEASE_NAME }}
          export NAMESPACE=${{ env.NAMESPACE }}

          # Make scripts executable
          chmod +x test-k8s-dataflow.sh

          # Run dataflow test
          echo "Running dataflow test..."
          ./test-k8s-dataflow.sh

      - name: Show cluster status on failure
        if: failure()
        run: |
          echo "=== Container Runtime Status ==="
          ${{ env.CONTAINER_RUNTIME }} --version || true
          ${{ env.CONTAINER_RUNTIME }} info || true
          ${{ env.CONTAINER_RUNTIME }} ps -a || true
          ${{ env.CONTAINER_RUNTIME }} images | head -10 || true

          echo "=== Kind Status ==="
          kind version || true
          kind get clusters || true

          echo "=== Cluster Status ==="
          kubectl cluster-info || true
          kubectl version || true

          echo "=== Pods Status ==="
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide || true
          kubectl get pods --all-namespaces | head -20 || true

          echo "=== Services Status ==="
          kubectl get services -n ${{ env.NAMESPACE }} || true

          echo "=== Events ==="
          kubectl get events -n ${{ env.NAMESPACE }} --sort-by='.lastTimestamp' || true
          kubectl get events --all-namespaces --sort-by='.lastTimestamp' | head -20 || true

          echo "=== Persistent Volumes ==="
          kubectl get pv,pvc -n ${{ env.NAMESPACE }} || true

          echo "=== Node Status ==="
          kubectl get nodes -o wide || true
          kubectl describe nodes || true

          echo "=== Recent Logs ==="
          for pod in $(kubectl get pods -n ${{ env.NAMESPACE }} -o name | head -5); do
            echo "--- Logs for $pod ---"
            kubectl logs -n ${{ env.NAMESPACE }} $pod --tail=20 || true
            kubectl logs -n ${{ env.NAMESPACE }} $pod --previous --tail=10 || true
          done

          echo "=== Container Logs ==="
          for container in $(${{ env.CONTAINER_RUNTIME }} ps --filter "label=io.x-k8s.kind.cluster=${{ env.KIND_CLUSTER_NAME }}" --format "{{.Names}}" | head -3); do
            echo "--- ${{ env.CONTAINER_RUNTIME }} logs for $container ---"
            ${{ env.CONTAINER_RUNTIME }} logs $container --tail=20 || true
          done

          echo "=== System Resources ==="
          df -h || true
          free -h || true
          top -bn1 | head -20 || true

      - name: Cleanup
        if: always()
        run: |
          kind delete cluster --name ${{ env.KIND_CLUSTER_NAME }} || true
