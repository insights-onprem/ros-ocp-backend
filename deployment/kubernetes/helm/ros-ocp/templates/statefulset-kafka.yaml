apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "ros-ocp.fullname" . }}-kafka
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "ros-ocp.labels" . | nindent 4 }}
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
spec:
  serviceName: {{ include "ros-ocp.fullname" . }}-kafka
  replicas: 1
  selector:
    matchLabels:
      {{- include "ros-ocp.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: kafka
      app.kubernetes.io/name: kafka
  template:
    metadata:
      labels:
        {{- include "ros-ocp.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: kafka
    spec:
      {{- with .Values.global.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- /*
      Init container to prepare Kafka data directory structure.

      PROBLEM: Kafka fails when it finds filesystem metadata directories like 'lost+found'
      in its log directory. These directories are automatically created by certain filesystems
      (ext2/3/4) at the root of mounted volumes for recovery purposes.

      SOLUTION: Use a subdirectory approach where:
      - Volume is mounted at /var/lib/kafka/data (may contain lost+found)
      - Kafka uses /var/lib/kafka/data/logs (clean subdirectory)
      - This completely isolates Kafka data from filesystem metadata

      BENEFITS:
      - Works with any storage class (OpenShift OCS, KIND local-path, cloud storage)
      - No need to clean lost+found on every restart
      - Cleaner separation of concerns
      - Compatible with both vanilla Kubernetes and OpenShift
      */}}
      initContainers:
        - name: prepare-kafka-data
          image: "{{ .Values.global.initContainers.waitFor.repository }}:{{ .Values.global.initContainers.waitFor.tag }}"
          imagePullPolicy: {{ .Values.global.pullPolicy }}
          command: ['sh', '-c']
          args:
            - |
              echo "Preparing Kafka data directory structure..."

              # Create the logs subdirectory where Kafka will store its data
              mkdir -p /var/lib/kafka/data/logs

              # Set appropriate permissions for Kafka user (UID 1000 in most Kafka images)
              # Use || true to handle cases where we can't change ownership (some storage classes)
              chown -R 1000:1000 /var/lib/kafka/data/logs 2>/dev/null || true

              # Show directory structure for debugging
              echo "Kafka data directory structure:"
              ls -la /var/lib/kafka/data/
              echo "Kafka logs directory prepared successfully"
          volumeMounts:
            - name: kafka-storage
              mountPath: /var/lib/kafka/data
      containers:
        - name: kafka
          image: "{{ .Values.kafka.broker.image.repository }}:{{ .Values.kafka.broker.image.tag }}"
          imagePullPolicy: {{ .Values.global.pullPolicy }}
          ports:
            - name: kafka
              containerPort: {{ .Values.kafka.broker.port }}
              protocol: TCP
          env:
            - name: KAFKA_ADVERTISED_LISTENERS
              value: PLAINTEXT://{{ include "ros-ocp.fullname" . }}-kafka:{{ .Values.kafka.broker.port }}
            - name: KAFKA_BROKER_ID
              value: {{ .Values.kafka.broker.brokerId | quote }}
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: {{ .Values.kafka.broker.offsetsTopicReplicationFactor | quote }}
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: {{ include "ros-ocp.fullname" . }}-zookeeper:{{ .Values.kafka.zookeeper.clientPort }}
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: {{ .Values.kafka.broker.autoCreateTopicsEnable | quote }}
            - name: KAFKA_LISTENERS
              value: PLAINTEXT://0.0.0.0:{{ .Values.kafka.broker.port }}
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: PLAINTEXT:PLAINTEXT
            - name: KAFKA_LOG_DIRS
              value: /var/lib/kafka/data/logs
          volumeMounts:
            - name: kafka-storage
              mountPath: /var/lib/kafka/data
          livenessProbe:
            tcpSocket:
              port: {{ .Values.kafka.broker.port }}
            initialDelaySeconds: 60
            periodSeconds: {{ .Values.probes.periodSeconds }}
            timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
            failureThreshold: {{ .Values.probes.failureThreshold }}
          readinessProbe:
            tcpSocket:
              port: {{ .Values.kafka.broker.port }}
            initialDelaySeconds: 30
            periodSeconds: {{ .Values.probes.periodSeconds }}
            timeoutSeconds: {{ .Values.probes.timeoutSeconds }}
            failureThreshold: {{ .Values.probes.failureThreshold }}
          resources:
            {{- toYaml .Values.resources.kafka | nindent 12 }}
  volumeClaimTemplates:
    - metadata:
        name: kafka-storage
      spec:
        accessModes: [ "ReadWriteOnce" ]
        volumeMode: {{ include "ros-ocp.volumeMode" . }}
        storageClassName: {{ include "ros-ocp.storageClass" . }}
        resources:
          requests:
            storage: {{ .Values.kafka.broker.storage.size }}